#!/usr/bin/env bash
set -euo pipefail

JAILED_VERSION="0.1.0"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# --- Defaults (from env vars) ---
IMAGE_NAME="${JAILED_IMAGE:-jailed:latest}"
USERNAME="${JAILED_USER:-coder}"
SYNC_STRATEGY="${JAILED_SYNC_STRATEGY:-mutagen}"
CONFIG_DIR="${JAILED_CONFIG_DIR:-${XDG_CONFIG_HOME:-$HOME/.config}/jailed}"
RUNTIME=""
TESTCONTAINERS=false
PROJECT_DIR=""

# --- Colors ---
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

info()    { echo -e "${BLUE}[jailed]${NC} $1"; }
success() { echo -e "${GREEN}[jailed]${NC} $1"; }
warn()    { echo -e "${YELLOW}[jailed]${NC} $1"; }
error()   { echo -e "${RED}[jailed]${NC} $1" >&2; }
die()     { error "$1"; exit 1; }

# --- Runtime detection ---
# Priority: --runtime flag > JAILED_RUNTIME env > podman in PATH > docker in PATH > error
detect_runtime() {
    if [ -n "$RUNTIME" ]; then
        command -v "$RUNTIME" >/dev/null 2>&1 || die "Runtime '$RUNTIME' not found in PATH"
        return
    fi

    if [ -n "${JAILED_RUNTIME:-}" ]; then
        RUNTIME="$JAILED_RUNTIME"
        command -v "$RUNTIME" >/dev/null 2>&1 || die "Runtime '$RUNTIME' (from JAILED_RUNTIME) not found in PATH"
        return
    fi

    if command -v podman >/dev/null 2>&1; then
        RUNTIME="podman"
    elif command -v docker >/dev/null 2>&1; then
        RUNTIME="docker"
    else
        die "Neither 'docker' nor 'podman' found in PATH. Install one and try again."
    fi
}

# --- Config directory setup ---
ensure_config_dirs() {
    local dirs=(
        "$CONFIG_DIR/agents/claude"
        "$CONFIG_DIR/agents/opencode"
        "$CONFIG_DIR/agents/opencode-data"
        "$CONFIG_DIR/agents/aider"
        "$CONFIG_DIR/agents/kimi"
        "$CONFIG_DIR/agents/gemini"
        "$CONFIG_DIR/agents/codex"
        "$CONFIG_DIR/agents/copilot"
        "$CONFIG_DIR/agents/gh"
        "$CONFIG_DIR/sessions"
        "$CONFIG_DIR/cache"
    )
    for dir in "${dirs[@]}"; do
        mkdir -p "$dir"
    done
}

# --- State file management ---
STATE_FILE="$CONFIG_DIR/running.json"

require_jq() {
    if ! command -v jq >/dev/null 2>&1; then
        error "jq is required for multi-project support but not found in PATH"
        error "Install jq:"
        error "  macOS:  brew install jq"
        error "  Linux:  apt install jq (Debian/Ubuntu) or yum install jq (RHEL/CentOS)"
        die "Cannot continue without jq"
    fi
}

write_state_file() {
    local container_name="$1"
    local -n projects_array=$2

    # Validate inputs
    [ -z "$container_name" ] && die "Container name cannot be empty"

    require_jq

    # Atomic write: build JSON in temp file, then move to final location
    local temp_file=$(mktemp "${STATE_FILE}.XXXXXX") || die "Failed to create temporary file"
    local old_trap=$(trap -p EXIT)
    trap "rm -f '$temp_file'" EXIT

    # Build JSON object from associative array
    local projects_json="{}"
    for name in "${!projects_array[@]}"; do
        projects_json=$(echo "$projects_json" | jq --arg k "$name" --arg v "${projects_array[$name]}" '. + {($k): $v}') || die "Failed to build projects JSON"
    done

    jq -n \
        --arg container "$container_name" \
        --arg runtime "$RUNTIME" \
        --arg sync "$SYNC_STRATEGY" \
        --argjson projects "$projects_json" \
        '{
            container: $container,
            runtime: $runtime,
            sync: $sync,
            projects: $projects
        }' > "$temp_file" || die "Failed to write state file"

    mv "$temp_file" "$STATE_FILE" || die "Failed to save state file"

    # Restore previous trap
    if [ -n "$old_trap" ]; then
        eval "$old_trap"
    else
        trap - EXIT
    fi
}

get_running_container() {
    if [ ! -f "$STATE_FILE" ]; then
        echo ""
        return
    fi

    require_jq
    jq -r '.container // ""' "$STATE_FILE" 2>/dev/null || echo ""
}

is_container_alive() {
    local container_name="$1"
    "$RUNTIME" inspect "$container_name" >/dev/null 2>&1
}

add_project_to_state() {
    local project_name="$1"
    local project_path="$2"

    require_jq

    if [ ! -f "$STATE_FILE" ]; then
        die "State file does not exist. Cannot add project."
    fi

    # Atomic write: read -> modify -> write to temp -> move
    local temp_file=$(mktemp "${STATE_FILE}.XXXXXX") || die "Failed to create temporary file"
    local old_trap=$(trap -p EXIT)
    trap "rm -f '$temp_file'" EXIT

    jq \
        --arg name "$project_name" \
        --arg path "$project_path" \
        '.projects[$name] = $path' \
        "$STATE_FILE" > "$temp_file" || die "Failed to update state file"

    mv "$temp_file" "$STATE_FILE" || die "Failed to save state file"

    # Restore previous trap
    if [ -n "$old_trap" ]; then
        eval "$old_trap"
    else
        trap - EXIT
    fi
}

remove_project_from_state() {
    local project_name="$1"

    require_jq

    if [ ! -f "$STATE_FILE" ]; then
        return
    fi

    # Atomic write: read -> modify -> write to temp -> move
    local temp_file=$(mktemp "${STATE_FILE}.XXXXXX") || die "Failed to create temporary file"
    local old_trap=$(trap -p EXIT)
    trap "rm -f '$temp_file'" EXIT

    jq \
        --arg name "$project_name" \
        'del(.projects[$name])' \
        "$STATE_FILE" > "$temp_file" || die "Failed to update state file"

    mv "$temp_file" "$STATE_FILE" || die "Failed to save state file"

    # Restore previous trap
    if [ -n "$old_trap" ]; then
        eval "$old_trap"
    else
        trap - EXIT
    fi
}

delete_state_file() {
    rm -f "$STATE_FILE"
}

# --- Podman + Mutagen shim setup ---
# Sets up environment for mutagen to work with Podman on macOS/Linux:
# 1. Exports DOCKER_HOST pointing to the Podman socket
# 2. Creates a docker->podman symlink shim for mutagen's CLI calls
# 3. Restarts mutagen daemon to pick up the new environment
setup_podman_mutagen_shim() {
    local podman_socket=""
    # Try platform-appropriate socket paths
    if [ "$(uname)" = "Darwin" ]; then
        # macOS: Podman runs in a VM, socket is in user's data dir
        for candidate in \
            "$HOME/.local/share/containers/podman/machine/podman.sock" \
            "$(podman machine inspect --format '{{.ConnectionInfo.PodmanSocket.Path}}' 2>/dev/null)"; do
            if [ -S "$candidate" ]; then
                podman_socket="$candidate"
                break
            fi
        done
    else
        # Linux: standard XDG runtime dir
        local candidate="${XDG_RUNTIME_DIR:-/run/user/$(id -u)}/podman/podman.sock"
        if [ -S "$candidate" ]; then
            podman_socket="$candidate"
        fi
    fi

    if [ -n "$podman_socket" ]; then
        export DOCKER_HOST="unix://${podman_socket}"
    else
        warn "Podman socket not found. Mutagen sync may fail."
    fi

    # Mutagen shells out to "docker" CLI. Create a persistent shim directory
    # in cache so it finds podman when docker isn't installed.
    if ! command -v docker >/dev/null 2>&1; then
        local shim_dir="$HOME/.cache/jailed/docker-shim"
        local podman_path
        podman_path=$(command -v podman) || die "podman not found in PATH"

        mkdir -p "$shim_dir"
        ln -sf "$podman_path" "$shim_dir/docker"
        export PATH="$shim_dir:$PATH"
    fi

    # Mutagen runs a long-lived daemon that inherits PATH at startup.
    # Restart it so it picks up DOCKER_HOST and the docker shim above.
    mutagen daemon stop 2>/dev/null || true
}

# --- Image check ---
image_exists() {
    "$RUNTIME" image inspect "$IMAGE_NAME" >/dev/null 2>&1
}

# --- Build ---
cmd_build() {
    local build_username="$USERNAME"

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --name) build_username="$2"; shift 2 ;;
            *) die "Unknown build option: $1" ;;
        esac
    done

    info "Building image '$IMAGE_NAME' (username: $build_username)..."
    "$RUNTIME" build \
        --build-arg "USERNAME=$build_username" \
        --build-arg "USER_UID=$(id -u)" \
        --build-arg "USER_GID=$(id -g)" \
        -t "$IMAGE_NAME" \
        "$SCRIPT_DIR"
    success "Image built successfully."
}

# --- Mutagen helpers ---
mutagen_available() {
    command -v mutagen >/dev/null 2>&1
}

start_mutagen_sync() {
    local host_dir="$1"
    local container_name="$2"
    local project_name="$3"

    if ! mutagen_available; then
        warn "Mutagen not found. Install it for better file sync performance:"
        warn "  macOS:  brew install mutagen-io/mutagen/mutagen"
        warn "  Linux:  https://github.com/mutagen-io/mutagen/releases"
        warn "Falling back to bind mount."
        SYNC_STRATEGY="bind"
        return 1
    fi

    mutagen sync create \
        --name="jailed-${container_name}-${project_name}" \
        --sync-mode=two-way-resolved \
        --ignore=".git" \
        --default-owner-beta="$USERNAME" \
        "$host_dir" \
        "docker://${USERNAME}@${container_name}/workspace/${project_name}" \
        || return 1

    info "Mutagen sync started (session: jailed-${container_name}-${project_name})"
}

stop_mutagen_sync() {
    local container_name="$1"
    local project_name="$2"
    if mutagen_available; then
        mutagen sync terminate "jailed-${container_name}-${project_name}" 2>/dev/null || true
    fi
}

stop_mutagen_sync_strict() {
    local container_name="$1"
    local project_name="$2"
    local session_name="jailed-${container_name}-${project_name}"

    if ! mutagen_available; then
        die "Mutagen not found. Cannot safely stop sync for '$project_name'."
    fi

    # 1. Check session exists (already gone = safe)
    if ! mutagen sync list "$session_name" >/dev/null 2>&1; then
        warn "No sync session found for '$project_name'. Skipping sync shutdown."
        return 0
    fi

    # 2. Flush in-flight changes
    info "Flushing sync for '$project_name'..."
    if ! mutagen sync flush "$session_name"; then
        error "Sync flush failed for '$project_name'. Files left intact."
        return 1
    fi

    # 3. Terminate the session
    info "Terminating sync for '$project_name'..."
    if ! mutagen sync terminate "$session_name"; then
        error "Sync terminate failed for '$project_name'. Files left intact."
        return 1
    fi

    # 4. Verify session is gone
    if mutagen sync list "$session_name" >/dev/null 2>&1; then
        error "Sync session still exists for '$project_name'. Refusing to delete files."
        return 1
    fi

    return 0
}

stop_all_mutagen_syncs() {
    local container_name="$1"

    if [ ! -f "$STATE_FILE" ]; then
        return
    fi

    require_jq

    # Get all project names from state file
    local project_names
    project_names=$(jq -r '.projects | keys[]' "$STATE_FILE" 2>/dev/null) || return

    # Stop each mutagen sync session
    while IFS= read -r project_name; do
        [ -n "$project_name" ] && stop_mutagen_sync "$container_name" "$project_name"
    done <<< "$project_names"
}

# --- Build container run arguments ---
build_run_args() {
    local container_name="$1"
    local -n _args=$2

    # Mutagen mode runs detached; bind mode runs interactive
    local run_flags="-it"
    if [ "$SYNC_STRATEGY" = "mutagen" ]; then
        run_flags="-d"
    fi

    _args=(
        run $run_flags --rm
        --name "$container_name"
        --hostname "jailed"
        -e "HOST_UID=$(id -u)"
        -e "HOST_GID=$(id -g)"
        -e "JAILED_USER=$USERNAME"
        -e "TERM=${TERM:-xterm-256color}"
    )

    # SELinux label for Podman bind mounts (:z = shared context)
    # The Podman VM runs SELinux in Enforcing mode; without this label
    # the container process is denied read/write access to bind mounts.
    local vol_suffix=""
    if [ "$RUNTIME" = "podman" ]; then
        vol_suffix=":z"
    fi

    # Config bind mounts (all 7 agents + sessions)
    _args+=(-v "$CONFIG_DIR/agents/claude:/home/$USERNAME/.claude${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/opencode:/home/$USERNAME/.config/opencode${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/opencode-data:/home/$USERNAME/.local/share/opencode${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/aider:/home/$USERNAME/.aider${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/kimi:/home/$USERNAME/.kimi${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/gemini:/home/$USERNAME/.gemini${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/codex:/home/$USERNAME/.codex${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/copilot:/home/$USERNAME/.config/github-copilot${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/agents/gh:/home/$USERNAME/.config/gh${vol_suffix}")
    _args+=(-v "$CONFIG_DIR/sessions:/home/$USERNAME/.jailed-sessions${vol_suffix}")

    if [ -f "$CONFIG_DIR/agents/.claude.json" ]; then
        _args+=(-v "$CONFIG_DIR/agents/.claude.json:/home/$USERNAME/.claude.json${vol_suffix}")
    fi

    if [ -f "$CONFIG_DIR/agents/.claude.json.backup" ]; then
        _args+=(-v "$CONFIG_DIR/agents/.claude.json.backup:/home/$USERNAME/.claude.json.backup${vol_suffix}")
    fi

    # Project directory mounts are added by cmd_run() after this function returns
    # (only for bind mode; mutagen syncs separately)

    # Runtime-specific security flags
    if [ "$RUNTIME" = "podman" ]; then
        _args+=(--userns=keep-id)
    else
        _args+=(--security-opt no-new-privileges)
        _args+=(--cap-drop ALL)
        _args+=(--cap-add SETUID --cap-add SETGID)
        _args+=(--read-only)
        _args+=(--tmpfs /tmp)
        _args+=(--tmpfs /run)
        _args+=(--tmpfs "/home/$USERNAME/.cache")
        _args+=(--tmpfs "/home/$USERNAME/.config:mode=1777")
        _args+=(--tmpfs "/home/$USERNAME/.local:mode=1777")
    fi

    # Testcontainers socket mount (opt-in via --testcontainers flag)
    if [ "$TESTCONTAINERS" = true ]; then
        local socket_path=""
        if [ "$RUNTIME" = "podman" ]; then
            socket_path="${XDG_RUNTIME_DIR:-/run/user/$(id -u)}/podman/podman.sock"
        else
            socket_path="/var/run/docker.sock"
        fi

        if [ -S "$socket_path" ]; then
            _args+=(-v "${socket_path}:/var/run/docker.sock")
            _args+=(-e "DOCKER_HOST=unix:///var/run/docker.sock")
            info "Socket mounted from $socket_path"
        else
            warn "Socket not found at $socket_path -- Testcontainers will not work"
        fi
    fi

    _args+=("$IMAGE_NAME")
}

# --- Dedupe project names ---
dedupe_project_names() {
    local -a paths=("$@")
    local -A base_count=()
    local -A result=()
    local -A used_names=()

    # Count basenames
    for p in "${paths[@]}"; do
        local base; base=$(basename "$p")
        base_count["$base"]=$(( ${base_count["$base"]:-0} + 1 ))
    done

    # Assign names - prefix with parent if duplicate, handle collisions
    for p in "${paths[@]}"; do
        local base; base=$(basename "$p")
        local candidate
        if [ "${base_count[$base]}" -gt 1 ]; then
            local parent; parent=$(basename "$(dirname "$p")")
            candidate="${parent}-${base}"

            # Handle collision by adding numeric suffix
            local count=2
            while [ -n "${used_names[$candidate]:-}" ]; do
                candidate="${parent}-${base}-${count}"
                ((count++))
            done
        else
            candidate="$base"
            # Still check for collision (edge case)
            local count=2
            while [ -n "${used_names[$candidate]:-}" ]; do
                candidate="${base}-${count}"
                ((count++))
            done
        fi
        result["$p"]="$candidate"
        used_names["$candidate"]=1
    done

    # Output: "name=path" lines
    for p in "${paths[@]}"; do
        echo "${result[$p]}=$p"
    done
}

# --- Run command ---
cmd_run() {
    # Parse project paths (default to current directory if none provided)
    local -a project_paths=()
    if [ $# -eq 0 ]; then
        project_paths=("$(pwd)")
    else
        while [[ $# -gt 0 ]]; do
            local path="$1"
            shift
            # Resolve to absolute path
            if [ ! -d "$path" ]; then
                die "Not a directory: $path"
            fi
            path="$(cd "$path" && pwd)"
            project_paths+=("$path")
        done
    fi

    # First run experience: prompt to build if no image found
    if ! image_exists; then
        warn "Image '$IMAGE_NAME' not found."
        read -rp "Build now? [Y/n] " answer
        case "${answer:-Y}" in
            [Yy]*) cmd_build ;;
            *) die "Cannot run without an image. Run 'jailed build' first." ;;
        esac
    fi

    ensure_config_dirs

    # Check if container already running
    local existing_container
    existing_container=$(get_running_container)
    if [ -n "$existing_container" ]; then
        if is_container_alive "$existing_container"; then
            die "Container already running: $existing_container. Use 'jailed shell' to reconnect or 'jailed stop' to shut down."
        else
            warn "Stale state file detected. Cleaning up..."
            delete_state_file
        fi
    fi

    # Generate project name->path mappings (dedupe basenames)
    local -a project_entries=()
    while IFS= read -r entry; do
        project_entries+=("$entry")
    done < <(dedupe_project_names "${project_paths[@]}")

    # Generate unique container name from first project dir + random suffix
    local first_project_name="${project_entries[0]%%=*}"
    local rand_suffix
    rand_suffix=$(head -c 4 /dev/urandom | od -An -tx1 | tr -d ' \n')
    local container_name="jailed-${first_project_name}-${rand_suffix}"

    # Build associative array for state file
    local -A projects_map=()
    for entry in "${project_entries[@]}"; do
        local name="${entry%%=*}"
        local path="${entry#*=}"
        projects_map["$name"]="$path"
    done

    # For Podman with mutagen: set DOCKER_HOST to the Podman socket path
    # so mutagen can use it as a Docker-compatible endpoint
    if [ "$RUNTIME" = "podman" ] && [ "$SYNC_STRATEGY" = "mutagen" ]; then
        setup_podman_mutagen_shim
    fi

    # Build base container args (without project mounts)
    local run_args=()
    build_run_args "$container_name" run_args

    # Add project bind mounts (bind mode only)
    if [ "$SYNC_STRATEGY" = "bind" ]; then
        local vol_suffix=""
        if [ "$RUNTIME" = "podman" ]; then
            vol_suffix=":z"
        fi

        for entry in "${project_entries[@]}"; do
            local name="${entry%%=*}"
            local path="${entry#*=}"
            run_args+=(-v "${path}:/workspace/${name}${vol_suffix}")
        done
    fi

    info "Starting jailed container..."
    info "Projects: ${#project_paths[@]}"
    for entry in "${project_entries[@]}"; do
        local name="${entry%%=*}"
        local path="${entry#*=}"
        info "  - $name: $path"
    done
    info "Runtime: $RUNTIME"
    info "Sync: $SYNC_STRATEGY"
    info "Container: $container_name"

    # Start container
    if [ "$SYNC_STRATEGY" = "mutagen" ]; then
        # For mutagen: start container detached (-d), start syncs, write state, then attach
        "$RUNTIME" "${run_args[@]}" sleep infinity

        # Set cleanup trap before starting syncs (in case of interruption)
        trap '"$RUNTIME" stop "$container_name" 2>/dev/null || true' EXIT

        # Start mutagen sync for each project
        local mutagen_failed=false
        for entry in "${project_entries[@]}"; do
            local name="${entry%%=*}"
            local path="${entry#*=}"
            if ! start_mutagen_sync "$path" "$container_name" "$name"; then
                mutagen_failed=true
                break
            fi
        done

        if [ "$mutagen_failed" = true ]; then
            # Fallback to bind mode
            warn "Mutagen sync failed. Falling back to bind mode..."
            "$RUNTIME" stop "$container_name" 2>/dev/null || true
            trap - EXIT

            # Rebuild args with bind mounts (don't mutate global SYNC_STRATEGY)
            run_args=()
            build_run_args "$container_name" run_args

            local vol_suffix=""
            if [ "$RUNTIME" = "podman" ]; then
                vol_suffix=":z"
            fi

            for entry in "${project_entries[@]}"; do
                local name="${entry%%=*}"
                local path="${entry#*=}"
                run_args+=(-v "${path}:/workspace/${name}${vol_suffix}")
            done

            # Update projects_map with bind strategy for state file
            local -A bind_projects_map=()
            for name in "${!projects_map[@]}"; do
                bind_projects_map["$name"]="${projects_map[$name]}"
            done

            # Write state file with bind strategy (pass by value, not reference)
            local temp_file=$(mktemp "${STATE_FILE}.XXXXXX") || die "Failed to create temporary file"
            local old_trap=$(trap -p EXIT)
            trap "rm -f '$temp_file'" EXIT

            local projects_json="{}"
            for name in "${!bind_projects_map[@]}"; do
                projects_json=$(echo "$projects_json" | jq --arg k "$name" --arg v "${bind_projects_map[$name]}" '. + {($k): $v}') || die "Failed to build projects JSON"
            done

            jq -n \
                --arg container "$container_name" \
                --arg runtime "$RUNTIME" \
                --arg sync "bind" \
                --argjson projects "$projects_json" \
                '{
                    container: $container,
                    runtime: $runtime,
                    sync: $sync,
                    projects: $projects
                }' > "$temp_file" || die "Failed to write state file"

            mv "$temp_file" "$STATE_FILE" || die "Failed to save state file"

            if [ -n "$old_trap" ]; then
                eval "$old_trap"
            else
                trap - EXIT
            fi

            # Run with bind mounts (interactive)
            # Phase 2: Clear trap before shell (container persists)
            trap - EXIT
            "$RUNTIME" "${run_args[@]}"

            # Shell exited - container still running
            info "Container still running. Use 'jailed shell' to reconnect or 'jailed stop' to shut down."
        else
            # Mutagen syncs started successfully
            # Write state file
            write_state_file "$container_name" projects_map

            # Attach to the running container interactively
            # Phase 2: Clear trap before shell (container persists)
            trap - EXIT
            "$RUNTIME" exec -it "$container_name" gosu "$USERNAME" zsh -l

            # Shell exited - container still running
            info "Container still running. Use 'jailed shell' to reconnect or 'jailed stop' to shut down."
        fi
    else
        # For bind mount: write state, run directly (interactive)
        write_state_file "$container_name" projects_map

        # Phase 2: No trap - container persists after shell exit
        trap - EXIT
        "$RUNTIME" "${run_args[@]}"

        # Shell exited - container still running
        info "Container still running. Use 'jailed shell' to reconnect or 'jailed stop' to shut down."
    fi
}

# --- Attach command (hot-attach additional project) ---
cmd_attach() {
    local project_path="${1:?Usage: jailed attach <path> [--container <name>]}"
    shift

    local container_override=""
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --container) container_override="$2"; shift 2 ;;
            *) die "Unknown option: $1" ;;
        esac
    done

    # 1. Check for jq dependency
    require_jq

    # 2. Get container name (from flag or state file)
    local container_name="$container_override"
    if [ -z "$container_name" ]; then
        container_name=$(get_running_container)
        if [ -z "$container_name" ]; then
            die "No running container found. Use --container flag or start a container first with 'jailed run'."
        fi
    fi

    # 3. Validate container is alive
    if ! is_container_alive "$container_name"; then
        die "Container '$container_name' is not running. Start it with 'jailed run' first."
    fi

    # 4. Read sync strategy from state file
    if [ ! -f "$STATE_FILE" ]; then
        die "State file not found. Cannot determine sync strategy."
    fi

    local sync_strategy
    sync_strategy=$(jq -r '.sync // ""' "$STATE_FILE" 2>/dev/null) || die "Failed to read sync strategy from state file"

    if [ "$sync_strategy" != "mutagen" ]; then
        die "Hot-attach requires mutagen sync. Restart with '--sync mutagen' or pass all project paths at launch."
    fi

    # 5. Resolve path to absolute and validate
    if [ ! -d "$project_path" ]; then
        die "Not a directory: $project_path"
    fi
    project_path="$(cd "$project_path" && pwd)"

    # 6. Check for duplicate project path
    local existing_project_path
    while IFS= read -r existing_project_path; do
        if [ "$existing_project_path" = "$project_path" ]; then
            die "Project already attached: $project_path"
        fi
    done < <(jq -r '.projects[]' "$STATE_FILE" 2>/dev/null)

    # 7. Generate project name (check existing names for deduplication)
    # Read existing project paths from state file
    local -a existing_paths=()
    while IFS= read -r path; do
        [ -n "$path" ] && existing_paths+=("$path")
    done < <(jq -r '.projects[]' "$STATE_FILE" 2>/dev/null)

    # Add new path to array for deduplication
    local -a all_paths=("${existing_paths[@]}" "$project_path")

    # Generate deduplicated names for all paths
    local -a project_entries=()
    while IFS= read -r entry; do
        project_entries+=("$entry")
    done < <(dedupe_project_names "${all_paths[@]}")

    # Extract the last entry (our new project)
    local new_project_entry="${project_entries[-1]}"
    local project_name="${new_project_entry%%=*}"

    info "Attaching project: $project_name"
    info "  Path: $project_path"
    info "  Container: $container_name"

    # 8. Create workspace directory in container
    "$RUNTIME" exec "$container_name" mkdir -p "/workspace/$project_name" || die "Failed to create workspace directory"

    # 9. Set ownership (chown to container user)
    "$RUNTIME" exec "$container_name" chown "$USERNAME:$USERNAME" "/workspace/$project_name" || die "Failed to set directory ownership"

    # 10. Setup Podman + Mutagen shim if needed
    if [ "$RUNTIME" = "podman" ]; then
        setup_podman_mutagen_shim
    fi

    # 11. Start mutagen sync
    if ! start_mutagen_sync "$project_path" "$container_name" "$project_name"; then
        die "Failed to start mutagen sync for project '$project_name'"
    fi

    # 12. Verify sync is actually running
    sleep 1
    if ! mutagen sync list "jailed-${container_name}-${project_name}" >/dev/null 2>&1; then
        die "Mutagen sync failed to initialize for project '$project_name'"
    fi

    # 13. Add project to state file (only after sync verified)
    add_project_to_state "$project_name" "$project_path"

    # 14. Success message and open shell in project directory
    success "Project '$project_name' attached successfully!"
    info "Opening shell in /workspace/$project_name..."
    "$RUNTIME" exec -it "$container_name" gosu "$USERNAME" zsh -c "cd /workspace/$project_name && exec zsh -l"

    # 15. On shell exit: container and sync stay alive
    info "Shell exited. Project remains attached. Container is still running."
}

# --- Detach command (remove project from running container) ---
cmd_detach() {
    local project_name="${1:?Usage: jailed detach <project-name>}"

    # 1. Check for jq dependency
    require_jq

    # 2. Get container name from state file
    local container_name
    container_name=$(get_running_container)
    [ -z "$container_name" ] && die "No running container found"

    # 3. Validate project exists in state file
    local project_path
    project_path=$(jq -r ".projects[\"$project_name\"] // empty" "$STATE_FILE")
    [ -z "$project_path" ] && die "Project '$project_name' not found. Run 'jailed ls' to see attached projects."

    # 4. Setup Podman shim if needed (for mutagen commands)
    if [ "$RUNTIME" = "podman" ]; then
        setup_podman_mutagen_shim
    fi

    # 5. Strict sync shutdown (GATE -- must succeed before file deletion)
    if ! stop_mutagen_sync_strict "$container_name" "$project_name"; then
        die "Sync shutdown failed. Project files left intact in /workspace/$project_name. Resolve the sync issue and retry."
    fi

    # 6. Delete /workspace/<project> inside container
    info "Removing /workspace/$project_name from container..."
    if ! "$RUNTIME" exec "$container_name" rm -rf "/workspace/$project_name"; then
        warn "Failed to remove /workspace/$project_name from container. Files may remain."
        # Non-fatal: sync is already stopped, so proceed with state cleanup
    fi

    # 7. Remove project from state file
    remove_project_from_state "$project_name"

    # 8. Success message
    success "Detached '$project_name' from $container_name"
}

# --- Shell command (reconnect to running container) ---
cmd_shell() {
    local project_name="${1:-}"

    # 1. Require jq
    require_jq

    # 2. Get container name from state file
    local container_name
    container_name=$(get_running_container)
    [ -z "$container_name" ] && die "No running container found. Start one with 'jailed run'."

    # 3. Validate container is alive
    if ! is_container_alive "$container_name"; then
        warn "Container '$container_name' is no longer running. Cleaning up..."
        delete_state_file
        die "Container is no longer running. Start a new one with 'jailed run'."
    fi

    # 4. Determine target directory
    if [ -n "$project_name" ]; then
        # Validate project exists in state
        local project_path
        project_path=$(jq -r ".projects[\"$project_name\"] // empty" "$STATE_FILE")
        [ -z "$project_path" ] && die "Project '$project_name' not found. Run 'jailed ls' to see attached projects."

        "$RUNTIME" exec -it "$container_name" gosu "$USERNAME" zsh -c "cd /workspace/$project_name && exec zsh -l"
    else
        # No project specified: auto-select if only one, otherwise /workspace
        local project_count
        project_count=$(jq '.projects | length' "$STATE_FILE")

        if [ "$project_count" -eq 1 ]; then
            local only_project
            only_project=$(jq -r '.projects | keys[0]' "$STATE_FILE")
            "$RUNTIME" exec -it "$container_name" gosu "$USERNAME" zsh -c "cd /workspace/$only_project && exec zsh -l"
        else
            "$RUNTIME" exec -it "$container_name" gosu "$USERNAME" zsh -l
        fi
    fi
}

# --- Stop command (full container teardown) ---
cmd_stop() {
    # 1. Require jq
    require_jq

    # 2. Get container name from state file
    local container_name
    container_name=$(get_running_container)

    if [ -z "$container_name" ]; then
        info "Nothing to stop."
        return
    fi

    # 3. Check if container is alive
    if ! is_container_alive "$container_name"; then
        warn "Container '$container_name' already stopped. Cleaning up state..."
        delete_state_file
        return
    fi

    # 4. Stop all mutagen syncs (best-effort, lenient)
    info "Stopping sync sessions..."
    if [ "$RUNTIME" = "podman" ]; then
        setup_podman_mutagen_shim
    fi
    stop_all_mutagen_syncs "$container_name"

    # 5. Stop the container
    info "Stopping container '$container_name'..."
    "$RUNTIME" stop "$container_name" 2>/dev/null || true

    # 6. Delete state file
    delete_state_file

    # 7. Success message
    success "Container stopped."
}

# --- List command (show running container and projects) ---
cmd_ls() {
    if [ ! -f "$STATE_FILE" ]; then
        info "No running containers"
        return
    fi
    require_jq
    local container_name; container_name=$(get_running_container)

    if ! is_container_alive "$container_name"; then
        warn "Container '$container_name' is no longer running. Cleaning up..."
        delete_state_file
        info "No running containers"
        return
    fi

    local runtime sync
    runtime=$(jq -r '.runtime' "$STATE_FILE")
    sync=$(jq -r '.sync' "$STATE_FILE")

    echo "Container: $container_name"
    echo "Runtime:   $runtime"
    echo "Sync:      $sync"
    echo ""
    echo "Projects:"
    jq -r '.projects | to_entries[] | "  \(.key) â†’ \(.value)"' "$STATE_FILE"
}

# --- Help ---
cmd_help() {
    cat <<'EOF'
jailed - Secure AI coding assistant container

Usage:
  jailed [path...]                    Start container with one or more projects
  jailed attach <path>                Attach project to running container (mutagen only)
  jailed detach <project-name>        Remove project from running container
  jailed shell [project-name]         Reconnect to running container shell
  jailed stop                         Stop container and clean up all resources
  jailed ls                           List running container and attached projects
  jailed build [--name USER]          Build/rebuild the container image
  jailed version                      Show version
  jailed help                         Show this help

Options:
  --runtime <docker|podman>    Container runtime (default: auto-detect)
  --testcontainers             Mount Docker/Podman socket for Testcontainers
  --sync <mutagen|bind>        Sync strategy (default: mutagen)
  --container <name>           Target container for attach command

Environment Variables:
  JAILED_RUNTIME               Force container runtime
  JAILED_IMAGE                 Custom image name (default: jailed:latest)
  JAILED_USER                  Container username (default: coder)
  JAILED_CONFIG_DIR            Config directory (default: ~/.config/jailed)
  JAILED_SYNC_STRATEGY         Sync strategy (default: mutagen)

AI Agents Available Inside Container:
  claude       Claude Code (Anthropic)
  opencode     OpenCode
  aider        Aider (AI pair programming)
  kimi         Kimi Code CLI
  gemini       Gemini CLI (Google)
  codex        Codex CLI (OpenAI)
  gh copilot   GitHub Copilot CLI

Security:
  - Non-root user with UID/GID matching host
  - Only project directory and config dirs accessible
  - No --privileged flag
  - Capabilities dropped (Docker)
  - Read-only root filesystem (Docker)
  - Rootless mode (Podman)
EOF
}

# --- Version ---
cmd_version() {
    echo "jailed $JAILED_VERSION"
}

# --- Main ---
main() {
    # Parse global flags before dispatching to subcommands
    local positional=()
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --runtime)
                RUNTIME="$2"; shift 2 ;;
            --testcontainers)
                TESTCONTAINERS=true; shift ;;
            --sync)
                SYNC_STRATEGY="$2"; shift 2 ;;
            *)
                positional+=("$1"); shift ;;
        esac
    done
    set -- "${positional[@]+"${positional[@]}"}"

    detect_runtime

    local command="${1:-}"

    case "$command" in
        build)   shift; cmd_build "$@" ;;
        run)     shift; cmd_run "$@" ;;
        attach)  shift; cmd_attach "$@" ;;
        detach)  shift; cmd_detach "$@" ;;
        shell)   shift; cmd_shell "$@" ;;
        stop)    cmd_stop ;;
        ls)      cmd_ls ;;
        version) cmd_version ;;
        help|--help|-h) cmd_help ;;
        *)       cmd_run "$@" ;;
    esac
}

main "$@"
